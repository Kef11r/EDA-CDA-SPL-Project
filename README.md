# EDA-CDA-SPL-Project
# stat_analyzer

`stat_analyzer` це невелика навчальна бібліотека для EDA та перевірки статистичних гіпотез на основі датасету, що вказаний у конфігурації з можливістю:

- виконувати базовий EDA (shape, пропуски, описова статистика, категоріальні частоти, кореляції)
- автоматично підбирати можливі статистичні тести на основі типів змінних
- запускати тести (Pearson, Spearman, t test, Mann Whitney, ANOVA, Kruskal, Chi square)
- використовувати наперед задані гіпотези з конфігурацій `presets.py`
- отримувати рекомендації від LLM (моделі через OpenRouter) щодо вибору тестів
- будувати базові графіки (гістограми, boxplot, heatmap, barplot, pairplot)
- взаємодіяти як через інтерфейс командного рядка, так і як звичайну Python бібліотеку через `import`


## 1. Встановлення та запуск через CLI

### 1.1. Клонування репозиторію

```bash
git clone <URL_твого_репозиторію>
cd EDA-CDA-SPL-Project
```

### 1.2. Створити та активувати віртуальне оточення
```bash
python -m venv .venv
# Windows PowerShell
.\.venv\Scripts\Activate.ps1
# або cmd
.\.venv\Scripts\activate.bat
```
### 1.3. Встановити залежності
```
pip install pandas scipy matplotlib seaborn
pip install langchain-openai langchain-core openai python-dotenv
```
### 1.4. Підготовка .env для АІ
```
OPENROUTER_URL="https://openrouter.ai/api/v1"
GEMINI_API_KEY="sk-or-v1-...тут_твій_OpenRouter_API_ключ..."
```
### 1.5. Запуск інтерфейсу

Запускати через термінал 'python -m stat_analyzer' python package
Вигляд меню:
```
=== Меню аналізу vgsales ===
1. Базовий EDA
2. Перевірити власну гіпотезу (обрати змінні)
3. Запустити всі наперед задані гіпотези
4. Побудувати графіки
0. Вихід
```

## 2. Використання бібліотеки через import
### 2.1. EDA функції (stat_analyzer.eda):
```
load_data(path: Path | str) завантажує CSV датасет

basic_info(df) друкує форму, типи, пропуски

numerical_summary(df, columns=None) повертає .describe() по числових

categorical_summary(df, columns=None, top_n=5) повертає топ значень по категоріях

correlation_matrix(df, columns=None) будує кореляційну матрицю по числових
```
### 2.2. Статистичні тести та авто підбір (stat_analyzer.hypothesis_tests):
```
suggest_tests(df, col1, col2) повертає список тестів для пари змінних

run_test_by_name(df, test_name, col1, col2) запускає відповідний тест

run_or_suggest(...) або запускає тест, або повертає список можливих
```
### 2.3. Візуалізації (stat_analyzer.hypothesis_tests.plots):
```
plot_histogram(df, column). Будує гістограму для числової змінної.
Використовується для оцінки розподілу даних, пошуку асиметрії, мод, вибросів.

plot_boxplot(df, column). Створює boxplot для вибраної числової змінної.
Дає змогу побачити медіану, межі квартилів та можливі аномалії.

plot_correlation_heatmap(df). Будує теплову карту кореляцій між усіма числовими змінними у датасеті.
Зручно для виявлення лінійних залежностей.

plot_bar_counts(df, column). Показує кількість появ кожної категорії у вибраній категоріальній змінній.
Корисно для аналізу балансу класів та частот.

plot_pairplot(df). Будує набір парних графіків (scatterplot matrix) між числовими змінними.
Дозволяє візуально оцінити можливі залежності та структуру даних.
```

### 2.4. Конфігурація тестів і кастомні функції
У бібліотеці передбачений файл `test_config.json`, який дозволяє користувачу:
- переглядати доступні статистичні тести
- вмикати або вимикати певні тести
- додавати власні користувацькі тести
- змінювати назви або опис тестів
- розширювати логіку системи без зміни коду бібліотеки

Структура файлу:
```
{
  "tests": {
    "pearson": {
      "enabled": true,
      "description": "Кореляція Пірсона для двох числових змінних"
    },
    "spearman": {
      "enabled": true,
      "description": "Кореляція Спірмена для монотонних зв'язків"
    },
    "anova": {
      "enabled": true,
      "description": "Порівняння середніх між кількома групами"
    },
    "my_custom_test": {
      "enabled": true,
      "description": "Мій власний тест, який я хочу додати"
    }
  }
}
```

Як додати власний тест?:
1. У файлі `test_config.json` додати опис нового тесту:
```
"my_ttest": {
  "enabled": true,
  "description": "Мій модифікований t test"
}
```
2. Створити Python функцію у hypothesis_tests/custom/:
```
def run_my_ttest(df, col1, col2):
    # ваша логіка
    return {
        "test_name": "my_ttest",
        "statistic": result_stat,
        "p_value": p,
        "alpha": 0.05
    }
```
3. Завантажити цю функцію через механізм:
```
from stat_analyzer.hypothesis_tests.runner import load_custom_test
```
# 3. Інтеграція з АІ
У бібліотеці реалізована інтеграція зі сторонніми LLM моделями через OpenRouter API. Механізм використовує модуль `stat_analyzer.ai.ai_agent`, який відповідає за те, щоб на основі гіпотези користувача і доступних статистичних тестів сформувати оптимальну рекомендацію.
### 3.1. Як AI використовується всередині бібліотеки
Під час аналізу даних користувач формує гіпотезу у вільній формі (українською або англійською мовою). Бібліотека:
1. Визначає типи змінних (числові або категоріальні).
2. Формує список можливих статистичних тестів на основі вибраних колонок.
3. Передає гіпотезу та доступні тести у AI агент.
4. Отримує від моделі рекомендацію у вигляді JSON структури:
   - `recommended_tests` список тестів у порядку пріоритету, обраних AI.
   - `explanation` коротке пояснення українською мовою.
5. Виводить рекомендацію користувачеві і дозволяє обрати тест.

### 3.2. Для чого AI використовується в бібліотеці
1. Інтерпретує зміст гіпотези. Користувач може сформувати гіпотезу будь як:
- "Чи впливає жанр гри на глобальні продажі"
- "Яка залежність між JP_Sales і NA_Sales"
- "Чи відрізняються європейські продажі між платформами"
2. Обирає найбільш доречні статистичні тести
- пріоритезувати Spearman над Pearson, якщо в гіпотезі згадується нелінійність
- обрати Mann Whitney замість t test, якщо формулювання явно натякає на нерівність варіансів або розподілів
- обрати chi2 для категоріальних порівнянь навіть якщо користувач цього не знає.
3. Пояснює вибір тестів користувачеві

# Статус проєкту
Ця бібліотека перебуває на початковому етапі розробки. Логіка вибору тестів, структура модулів, інтеграція з AI агентом, а також ефективність обчислень потребують подальшої оптимізації, розширення функціоналу і перегляду архітектурних рішень. Проєкт активно розвивається, тому можливі зміни у публічному API, форматах даних і механізмах виклику методів. Ваші пропозиції та зауваження вітаються.




